<CRANTaskView>

  <name>NaturalLanguageProcessing</name>
  <topic>Natural Language Processing</topic>
  <maintainer email="Fridolin.Wild@wu-wien.ac.at">Ingo Feinerer and Fridolin Wild</maintainer>
  <version>2008-09-16</version>
  
  <info>
      <p>This CRAN Task View contains a list of packages useful for
      natural language processing.</p>
      <h4>Lexical Databases:</h4>
      <ul>
	<li><pkg>wordnet</pkg> provides an R interface
	  to <a href="http://wordnet.princeton.edu/">WordNet</a>, a large
	  lexical database of English.
	</li>
      </ul>
	  <h4>Keyword Extraction and General String Manipulation:</h4>
	  <ul>
	<li>R's base package already provides a rich set of character manipulation
	routines. See <code>help.search(keyword = "character", package = "base")</code>
	for more information on these capabilities.
	</li>
	<li><pkg>RKEA</pkg> provides an R interface to <a
	  href="http://www.nzdl.org/Kea/">KEA</a> (Version 5.0). KEA (for
	  Keyphrase Extraction Algorithm) allows for extracting keyphrases from
	  text documents. It can be either used for free indexing or for indexing
	  with a controlled vocabulary.
	</li>
	<li><pkg>gsubfn</pkg> can be used for certain parsing tasks such as 
	  extracting words from strings by content rather than by delimiters.
	  demo("gsubfn-gries") shows an example of this in a natural language 
	  processing context.
	</li>
	  </ul>
      <h4>Natural Language Processing:</h4>
      <ul>
	<li><pkg>openNLP</pkg> provides an R interface
	  to <a href="http://opennlp.sourceforge.net/">OpenNLP</a>, a
	  collection of natural language processing tools including a
	  sentence detector, tokenizer, pos-tagger, shallow and full
	  syntactic parser, and named-entity detector, using the Maxent
	  Java package for training and using maximum entropy
	  models.
	</li>
	<li><pkg>openNLPmodels</pkg>
	  ships trained models for English and Spanish to be used
	  with <pkg>openNLP</pkg>.
	</li>
	<li><pkg>RWeka</pkg> is a interface
	  to <a href="http://www.cs.waikato.ac.nz/ml/weka/">Weka</a>
	  which is a collection of machine learning algorithms for data
	  mining tasks written in Java. Especially useful in the context
	  of natural language processing is its functionality for
	  tokenization and stemming.
	</li>
	<li><pkg>Snowball</pkg>
	  provides the Snowball stemmers which contain the Porter
	  stemmer and several other stemmers for different
	  languages. See
	  the <a href="http://snowball.tartarus.org/">Snowball</a>
	  webpage for details.
	</li>
	<li>Alternatively,
	  the <a href="http://www.omegahat.org">Omegahat</a>
	  package <a href="http://www.omegahat.org/Rstem/">Rstem</a>
	  provides an R interface to a C version of Porter's word
	  stemming algorithm.
	</li>
      </ul>
      <h4>String Kernels:</h4>
      <ul>
	<li><pkg>kernlab</pkg>
	  allows to create and compute with string kernels, like full string,
	  spectrum, or bounded range string kernels. It can directly use
	  the document format used
	  by <pkg>tm</pkg>
	  as input.
	</li>
      </ul>
      <h4>Text Mining:</h4>
      <ul>
	<li><pkg>tm</pkg>
	  provides a comprehensive text mining framework for
	  R. The <a href="http://www.jstatsoft.org/">Journal of Statistical Software</a>
	  article <a href="http://www.jstatsoft.org/v25/i05/">Text Mining
	  Infrastructure in R</a> gives a detailed overview and presents
	  techniques for count-based analysis methods, text clustering,
	  text classification and string kernels.
	</li>
	<li><pkg>lsa</pkg>
	  provides routines for performing a latent semantic analysis with R.
	  The basic idea of latent semantic analysis (LSA) is, 
      that text do have a higher order (=latent semantic) structure which, 
      however, is obscured by word usage (e.g. through the use of synonyms 
      or polysemy). By using conceptual indices that are derived statistically 
      via a truncated singular value decomposition (a two-mode factor analysis) 
      over a given document-term matrix, this variability problem can be overcome.
	  The article <a href="http://www.springerlink.com/content/g7u377132gq5623g/">Investigating 
	  Unstructured Texts with Latent Semantic Analysis</a>
	  gives a detailed overview and demonstrates the use of the package 
	  with examples from the are of technology-enhanced learning.
	</li>
	<li><pkg>corpora</pkg>
	  offers utility functions for the statistical analysis of corpus frequency data.
	</li>
	<li><pkg>languageR</pkg>
	  provides data sets and functions exemplifying statistical methods, and some 
	  facilitatory utility functions used in the book by R. H. Baayen: "Analyzing Linguistic Data: a Practical 
	  Introduction to Statistics Using R", Cambridge University Press, 2008.
	</li>
	<li><pkg>zipfR</pkg>
	  offers some statistical models for word frequency distributions. The
      utilities include functions for loading, manipulating and visualizing word frequency data and
      vocabulary growth curves. The package also implements several statistical models for the
      distribution of word frequencies in a population. (The name of this library derives from the
      most famous word frequency distribution, Zipf's law.)
	</li>
      </ul>
  </info>

  <packagelist>
    <pkg>corpora</pkg>
    <pkg>kernlab</pkg>
    <pkg>languageR</pkg>
    <pkg>lsa</pkg>
    <pkg>openNLP</pkg>
    <pkg>openNLPmodels</pkg>
    <pkg>RWeka</pkg>
    <pkg>Snowball</pkg>
    <pkg priority="core">tm</pkg>
    <pkg>wordnet</pkg>
    <pkg>zipfR</pkg>
    <pkg>gsubfn</pkg>
    <pkg>RKEA</pkg>
  </packagelist>

  <links>
    <view>Cluster</view>
    <view>MachineLearning</view>
    <a href="http://www.cogsci.uni-osnabrueck.de/~severt/SIGIL/index.html">A Gentle Introduction to Statistics for (Computational) Linguists (SIGIL)</a>
    <a href="http://wwwpeople.unil.ch/jean-pierre.mueller/archive_ttda.html">ttda: Tools for Textual Data Analysis (Deprecated)</a>
  </links>

</CRANTaskView>
