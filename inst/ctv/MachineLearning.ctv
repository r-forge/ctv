<CRANTaskView>

  <name>MachineLearning</name>
  <topic>Machine Learning &amp; Statistical Learning</topic>
  <maintainer>Torsten Hothorn</maintainer>
  
  <info>
    Several add-on packages implement ideas and methods developed at the
    borderline between computer science and statistics - this field of research
    is usually referred to as machine learning. 

    The packages can be roughly structured into the following topics:
    <ul>
      <li><i>Neural Networks</i>: Single-hidden-layer neural network are 
             implemented in package <tt>nnet</tt> as part of the <pkg>VR</pkg>
             bundle (shipped with base R). </li>
      <li><i>Recursive Partitioning</i>: Tree-structured models for
             regression, classification and survival analysis, following the
	     ideas in the CART book, are
             implemented in <pkg>rpart</pkg> (shipped with base R) and <pkg>tree</pkg>.
             An adaptation of <pkg>rpart</pkg> for multivariate responses
             is available in package <pkg>mvpart</pkg>. The validity of
             trees can be investigated via permutation approaches with package 
             <pkg>rpart.permutation</pkg> and a tree algorithm fitting 
             nearest neighbors in each node is implemented in package 
             <pkg>knnTree</pkg>. For problems with binary input variables
             the package <pkg>LogicReg</pkg> implements logic regression.
             Graphical tools for the visualization of
             trees are available in packages <pkg>maptree</pkg> and 
             <pkg>pinktoe</pkg>. A recursive partitioning algorithm based on
             conditional inference procedures with unbiased variable
             selection and statistical stopping criterion is implemented in package
             <pkg>party</pkg>. Extensible tools for visualizing binary trees are 
             available as well.</li>
      <li><i>Regularized and Shrinkage Methods</i>: Regression models with some
             constraint on the parameter estimates can be fitted with the
             <pkg>lasso2</pkg> and <pkg>lars</pkg> packages. The solutions
             for all values of the shrinkage parameter can be simultaneously 
             computed using the functionality in package <pkg>elasticnet</pkg>.
             The shrunken
             centroids classifier and utilities for gene expression analyses are
             implemented in package <pkg>pamr</pkg>.</li> 
      <li><i>Random Forests</i>: The reference implementation of the random
             forest algorithm for regression and classification is available in 
             package <pkg>randomForest</pkg>. Package <pkg>ipred</pkg> has bagging
             for regression, classification and survival analysis as well as
             bundling, a combination of multiple models via
             ensemble learning.</li>
      <li><i>Boosting</i>: Various forms of gradient boosting are
             implemented in packages <pkg>gbm</pkg> and <pkg>boost</pkg>.</li>
      <li><i>Support Vector Machines</i>: The function <tt>svm()</tt> from 
             <pkg>e1071</pkg> offers an interface to the LIBSVM library and
             package <pkg>kernlab</pkg> implements a flexible framework 
             for kernel learning (including SVMs, RVMs and other kernel
	     learning algorithms). An interface to the SVMlight implementation
	     (only for one-against-all classification) is provided in package
	     <pkg>klaR</pkg>.</li>
      <li><i>Association Rules</i>: For transaction data, the package
             <pkg>arules</pkg> provides both data structures for efficient
             handling of sparse binary data as well as interfaces to
             implementations of Apriori and Eclat for mining
             frequent itemsets, maximal frequent itemsets, closed frequent itemsets
             and association rules.</li>
      <li><i>Model selection and validation</i>: Package <pkg>e1071</pkg>
             has function <tt>tune()</tt> for hyper parameter tuning and 
             function <tt>errorest()</tt> (<pkg>ipred</pkg>) can be used for
             error rate estimation. The cost parameter C for support vector
             machines can be chosen utilizing the functionality of package
             <pkg>svmpath</pkg>.</li>
    </ul>
  </info>

  <packagelist>
    <pkg>arules</pkg>
    <pkg>boost</pkg>
    <pkg priority="core">e1071</pkg>
    <pkg>elasticnet</pkg>
    <pkg priority="core">gbm</pkg>
    <pkg>ipred</pkg>
    <pkg priority="core">kernlab</pkg>
    <pkg>klaR</pkg>
    <pkg>lars</pkg>
    <pkg>lasso2</pkg>
    <pkg>mvpart</pkg>
    <pkg>pamr</pkg>
    <pkg>party</pkg>
    <pkg>rpart.permutation</pkg>
    <pkg priority="core">randomForest</pkg>
    <pkg priority="core">rpart</pkg>
    <pkg>svmpath</pkg>
    <pkg>tree</pkg>
    <pkg priority="core">VR</pkg>
  </packagelist>

  <links>
    <a href="http://www.boosting.org/">Boosting Research Site</a>
  </links>

</CRANTaskView>
